{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel('DATA/final_train_s_dummies.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[['Tax Related', 'Number of Lawyers',\n",
    "     'Number of Legal Parties', 'Value formatted',\n",
    "       'Unified Contribution formatted', 'Milano', 'Bari', 'Bologna', 'Genova',\n",
    "       'Palermo', 'Napoli', 'Torino', 'Trento', 'Roma', \"L'Aquila\", 'Potenza',\n",
    "       'Perugia', 'Campobasso', 'Firenze', 'Cagliari', 'Venezia', 'Cosenza',\n",
    "       'Ancona', 'Trieste', 'Aosta','OR-140999', 'OR-145009', 'OR-139999',\n",
    "       'OR-145999', 'OR-130099', 'OR-101003', 'OR-130121', 'OR-130111',\n",
    "       'OR-130131', 'OR-101002', 'OR-180002', 'OSA-180002']]\n",
    "y=data['Settlement']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a style=background:yellow;color:black id='train_val_test_split'> Standardization and Split in training, validation and testing set </a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a style=color:deepsky> **You need to scale just the variables that are neither dummies nor boolean** </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_to_scale = X[['Number of Lawyers','Number of Legal Parties', 'Value formatted',\n",
    "       'Unified Contribution formatted']]\n",
    "X_not_to_scale = X[['Tax Related','Milano', 'Bari', 'Bologna', 'Genova',\n",
    "       'Palermo', 'Napoli', 'Torino', 'Trento', 'Roma', \"L'Aquila\", 'Potenza',\n",
    "       'Perugia', 'Campobasso', 'Firenze', 'Cagliari', 'Venezia', 'Cosenza',\n",
    "       'Ancona', 'Trieste', 'Aosta','OR-140999', 'OR-145009', 'OR-139999',\n",
    "       'OR-145999', 'OR-130099', 'OR-101003', 'OR-130121', 'OR-130111',\n",
    "       'OR-130131', 'OR-101002', 'OR-180002', 'OSA-180002']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y = pd.DataFrame(y)\n",
    "std_scale = StandardScaler()\n",
    "X_scaled = std_scale.fit_transform(X_to_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled_df = pd.DataFrame(X_scaled, columns=[X_to_scale.columns])\n",
    "X_scaled_df = pd.concat([X_scaled_df, X_not_to_scale], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X_scaled_df, y, random_state=0,\n",
    "                                                            test_size=0.1)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val,random_state=0,\n",
    "                                                            test_size=0.2  )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is useful just if you dind't merge the cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_val = pd.DataFrame(np.array(X_train_val), columns=[['Number of Lawyers',\n",
    "     'Number of Legal Parties', 'Value formatted',\n",
    "       'Unified Contribution formatted', 'Tax Related','Milano', 'Bari', 'Bologna', 'Genova',\n",
    "       'Palermo', 'Napoli', 'Torino', 'Trento', 'Roma', \"L'Aquila\", 'Potenza',\n",
    "       'Perugia', 'Campobasso', 'Firenze', 'Cagliari', 'Venezia', 'Cosenza',\n",
    "       'Ancona', 'Trieste', 'Aosta','OR-140999', 'OR-145009', 'OR-139999',\n",
    "       'OR-145999', 'OR-130099', 'OR-101003', 'OR-130121', 'OR-130111',\n",
    "       'OR-130131', 'OR-101002', 'OR-180002', 'OSA-180002']], index = X_train_val.index)\n",
    "\n",
    "X_test = pd.DataFrame(np.array(X_test), columns=[['Number of Lawyers',\n",
    "     'Number of Legal Parties', 'Value formatted',\n",
    "       'Unified Contribution formatted', 'Tax Related','Milano', 'Bari', 'Bologna', 'Genova',\n",
    "       'Palermo', 'Napoli', 'Torino', 'Trento', 'Roma', \"L'Aquila\", 'Potenza',\n",
    "       'Perugia', 'Campobasso', 'Firenze', 'Cagliari', 'Venezia', 'Cosenza',\n",
    "       'Ancona', 'Trieste', 'Aosta','OR-140999', 'OR-145009', 'OR-139999',\n",
    "       'OR-145999', 'OR-130099', 'OR-101003', 'OR-130121', 'OR-130111',\n",
    "       'OR-130131', 'OR-101002', 'OR-180002', 'OSA-180002']], index = X_test.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4575ad0",
   "metadata": {
    "id": "f4575ad0"
   },
   "source": [
    "## <a style=background:yellow;color:black id='reg_tree'> REGRESSION-TREE</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb402f2f",
   "metadata": {
    "id": "bb402f2f"
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "34018f77",
   "metadata": {
    "id": "34018f77",
    "outputId": "03eb7765-8fe8-4de1-e106-7fa686b3e810"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeRegressor(criterion=&#x27;absolute_error&#x27;, max_features=&#x27;sqrt&#x27;,\n",
       "                      min_samples_split=10, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeRegressor</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeRegressor(criterion=&#x27;absolute_error&#x27;, max_features=&#x27;sqrt&#x27;,\n",
       "                      min_samples_split=10, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeRegressor(criterion='absolute_error', max_features='sqrt',\n",
       "                      min_samples_split=10, random_state=42)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_tree = DecisionTreeRegressor(random_state=42, criterion='absolute_error',\n",
    "                                min_samples_split=10,\n",
    "                                max_features='sqrt')\n",
    "\n",
    "reg_tree.fit(X_train_val,y_train_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34a58d9",
   "metadata": {
    "id": "c34a58d9",
    "outputId": "537f811c-1583-40ee-f291-9ffabc166651"
   },
   "outputs": [],
   "source": [
    "y_pred = reg_tree.predict(X_test)\n",
    "residuals = np.ravel(np.array(y_pred)) - np.ravel(np.array(y_test))\n",
    "\n",
    "pd.DataFrame({'y_true':np.ravel(y_test), 'y_pred':np.ravel(y_pred), 'residuals':np.ravel(residuals)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47de9ed5",
   "metadata": {
    "id": "47de9ed5",
    "outputId": "de815817-4df4-4935-b0ad-ec440ccb0807"
   },
   "outputs": [],
   "source": [
    "y_pred_descaled = (y_pred*std_scale.var_**0.5)+std_scale.mean_\n",
    "y_val_descaled = (y_val*std_scale.var_**0.5)+std_scale.mean_\n",
    "print(mean_absolute_error(y_val_descaled, y_pred_descaled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9794534c",
   "metadata": {
    "id": "9794534c"
   },
   "outputs": [],
   "source": [
    "param_grid_1 = [{\"min_samples_leaf\": list(range(10,201,10)),\n",
    "                'min_samples_split': list(range(10,201,10)), \n",
    "                'max_depth': list(range(5,26,5))}]\n",
    "reg_tree = DecisionTreeRegressor(random_state=42)\n",
    "grid_search_1 = GridSearchCV(reg_tree, param_grid=param_grid_1, cv=5,\n",
    "                          scoring='neg_mean_squared_error',\n",
    "                          return_train_score=True,n_jobs=-1)\n",
    "\n",
    "grid_search_1.fit(X_train_val, y_train_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f57b474",
   "metadata": {
    "id": "8f57b474"
   },
   "outputs": [],
   "source": [
    "my_model_1 = grid_search_1.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75db0ce8",
   "metadata": {
    "id": "75db0ce8",
    "outputId": "5a82233f-712c-4d5c-b2d7-8db72e29da84"
   },
   "outputs": [],
   "source": [
    "my_model_1.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2af01d",
   "metadata": {
    "id": "5d2af01d"
   },
   "outputs": [],
   "source": [
    "y_pred = grid_search_1.predict(X_test)\n",
    "\n",
    "residuals = np.array(y_pred) - np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c1d14d",
   "metadata": {
    "id": "76c1d14d",
    "outputId": "360321da-f72b-4e5b-dded-c8813075744a"
   },
   "outputs": [],
   "source": [
    "print(mean_absolute_error(y_test, grid_search_1.predict(X_test)))\n",
    "print(mean_absolute_error(y_train_val, grid_search_1.predict(X_train_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca27704",
   "metadata": {
    "id": "2ca27704",
    "outputId": "928b3650-afc2-409f-ac1a-cdb646417310"
   },
   "outputs": [],
   "source": [
    "prova = pd.DataFrame({'y_true':y_test, 'Value':X_test['Value formatted'],\n",
    "                      'y_pred':y_pred, 'residuals':residuals})\n",
    "\n",
    "prova.sort_values('residuals')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a style=background:yellow;color:black> MARS (Check the R Script)</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12418d4",
   "metadata": {
    "id": "a12418d4"
   },
   "source": [
    "## <a style=background:yellow;color:black id='Random_Forest'> Random Forest </a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3HOlkkDISGlZ",
   "metadata": {
    "id": "3HOlkkDISGlZ"
   },
   "source": [
    "#### Without grid search"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "212870ec",
   "metadata": {
    "id": "212870ec"
   },
   "source": [
    "* You can use <a style=color:deepskyblue> **Out-of-Bag** </a> evaluation. Random forests are decision trees with bagging, therefore at each iteration we don't consider all the observations. On average, with big samples we just consider 63% of the training instances. The other 37% are not considered (of course this 37% changes for each estimator). We can use this 37% (called out-of-bag) instead of the test set. This could lead to better results since we're using more training instances.\n",
    "* When splitting a predictor having k possible unordered values, there are $2^{(k-1)}-1$ possible partitions of k values into two groups. The computation becomes unfeasible as k increases. We can simplify it with one-hot encoding, ordering the predictor classes according to the proportion falling into outcome 1; then we split this predictor as if it were an ordered predictor. However, having a fearly big (in terms of unique values (or levels)) categorical unordinal variable is not good for computation and for overfitting, therefore you should avoid such variables. \n",
    "* One major problem with trees is their high variance. Often a small change in the data can result in a very different series of splits. This is due to the hierarchical nature of the process (if an error occurs in the first split, then all the other splits can just make it worse and worse). A way to reduce this variance is to use Bagging.\n",
    "* The lack of smoothness of the predictions surfaces and the difficulty in capturing additive structure can be a problem for regression tasks. We can solve this problems by using <a style=color:deepskyblue> **MARS** </a> (Multivariate Additive Regression Splines)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7c7903",
   "metadata": {
    "id": "8a7c7903"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rnd_reg = RandomForestRegressor(n_estimators=50,\n",
    "                                #n_jobs=5,\n",
    "                                max_depth=10,\n",
    "                                criterion='absolute_error',\n",
    "                               random_state = 42,\n",
    "                               min_samples_split=20,\n",
    "                               min_samples_leaf=20,\n",
    "                               max_leaf_nodes=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17811dbe",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "17811dbe",
    "outputId": "6a83d955-a72a-4b41-b6e3-08f8ccd952cb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['str', 'tuple']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "<ipython-input-24-39257126c4b0>:1: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rnd_reg.fit(X_train_val, y_train_val)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(criterion='absolute_error', max_depth=10,\n",
       "                      min_samples_leaf=20, min_samples_split=20,\n",
       "                      n_estimators=50, random_state=42)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rnd_reg.fit(X_train_val, y_train_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "TbMUafG1MP-g",
   "metadata": {
    "id": "TbMUafG1MP-g"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename='rnd_reg_50_estimators.sav'\n",
    "#pickle.dump(rnd_reg_50_estimators, open(filename, 'wb')) \n",
    "rnd_reg = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590fa7b8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "590fa7b8",
    "outputId": "009606d8-1c45-4e12-9a22-8ff621af75e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "765.0234303933746\n",
      "727.9669157159126\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "y_pred = rnd_reg.predict(X_test)\n",
    "\n",
    "residuals = np.array(y_pred) - np.array(y_test)\n",
    "\n",
    "print(mean_absolute_error(y_test, y_pred))\n",
    "print(mean_absolute_error(y_train_val, rnd_reg.predict(X_train_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd1c44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # This chunk is for the MARS model.\n",
    "# final_train_s_dummies_std = pd.concat([X_test, X_train_val],axis=0 )\n",
    "# final_train_s_dummies_std['Settlement'] = pd.concat([y_test, y_train_val], axis = 0)\n",
    "# final_train_s_dummies_std.to_excel('final_train_s_dummies_std.xlsx')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6ea9f5e7",
   "metadata": {},
   "source": [
    "Let's destandardize X_train_val and X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "QL-H5SVLeN_t",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QL-H5SVLeN_t",
    "outputId": "b406ebde-6899-4e72-8981-58db46b26138"
   },
   "outputs": [],
   "source": [
    "X_train_val_inv_trans = pd.DataFrame(std_scale.inverse_transform(X_train_val[['Number of Lawyers','Number of Legal Parties', 'Value formatted',\n",
    "       'Unified Contribution formatted']]), columns = ['Number of Lawyers','Number of Legal Parties', 'Value formatted',\n",
    "       'Unified Contribution formatted'], index = X_train_val.index)\n",
    "\n",
    "X_test_inv_trans = pd.DataFrame(std_scale.inverse_transform(X_test[['Number of Lawyers','Number of Legal Parties', 'Value formatted',\n",
    "       'Unified Contribution formatted']]), columns = ['Number of Lawyers','Number of Legal Parties', 'Value formatted',\n",
    "       'Unified Contribution formatted'], index=X_test.index)\n",
    "\n",
    "X_train_val_not_std = X_train_val[['Tax Related','Milano', 'Bari', 'Bologna', 'Genova',\n",
    "       'Palermo', 'Napoli', 'Torino', 'Trento', 'Roma', \"L'Aquila\", 'Potenza',\n",
    "       'Perugia', 'Campobasso', 'Firenze', 'Cagliari', 'Venezia', 'Cosenza',\n",
    "       'Ancona', 'Trieste', 'Aosta','OR-140999', 'OR-145009', 'OR-139999',\n",
    "       'OR-145999', 'OR-130099', 'OR-101003', 'OR-130121', 'OR-130111',\n",
    "       'OR-130131', 'OR-101002', 'OR-180002', 'OSA-180002']]\n",
    "\n",
    "X_test_not_std = X_test[['Tax Related','Milano', 'Bari', 'Bologna', 'Genova',\n",
    "       'Palermo', 'Napoli', 'Torino', 'Trento', 'Roma', \"L'Aquila\", 'Potenza',\n",
    "       'Perugia', 'Campobasso', 'Firenze', 'Cagliari', 'Venezia', 'Cosenza',\n",
    "       'Ancona', 'Trieste', 'Aosta','OR-140999', 'OR-145009', 'OR-139999',\n",
    "       'OR-145999', 'OR-130099', 'OR-101003', 'OR-130121', 'OR-130111',\n",
    "       'OR-130131', 'OR-101002', 'OR-180002', 'OSA-180002']]\n",
    "\n",
    "X_train_val_destandardized = pd.concat([X_train_val_inv_trans, X_train_val_not_std],axis=1)\n",
    "X_test_destandardized = pd.concat([X_test_inv_trans, X_test_not_std],axis=1)\n",
    "\n",
    "X_train_val_destandardized = pd.DataFrame(np.array(X_train_val_destandardized), columns=[['Number of Lawyers',\n",
    "     'Number of Legal Parties', 'Value formatted',\n",
    "       'Unified Contribution formatted', 'Tax Related','Milano', 'Bari', 'Bologna', 'Genova',\n",
    "       'Palermo', 'Napoli', 'Torino', 'Trento', 'Roma', \"L'Aquila\", 'Potenza',\n",
    "       'Perugia', 'Campobasso', 'Firenze', 'Cagliari', 'Venezia', 'Cosenza',\n",
    "       'Ancona', 'Trieste', 'Aosta','OR-140999', 'OR-145009', 'OR-139999',\n",
    "       'OR-145999', 'OR-130099', 'OR-101003', 'OR-130121', 'OR-130111',\n",
    "       'OR-130131', 'OR-101002', 'OR-180002', 'OSA-180002']], index = X_train_val_destandardized.index)\n",
    "\n",
    "X_test_destandardized = pd.DataFrame(np.array(X_test_destandardized), columns=[['Number of Lawyers',\n",
    "     'Number of Legal Parties', 'Value formatted',\n",
    "       'Unified Contribution formatted', 'Tax Related','Milano', 'Bari', 'Bologna', 'Genova',\n",
    "       'Palermo', 'Napoli', 'Torino', 'Trento', 'Roma', \"L'Aquila\", 'Potenza',\n",
    "       'Perugia', 'Campobasso', 'Firenze', 'Cagliari', 'Venezia', 'Cosenza',\n",
    "       'Ancona', 'Trieste', 'Aosta','OR-140999', 'OR-145009', 'OR-139999',\n",
    "       'OR-145999', 'OR-130099', 'OR-101003', 'OR-130121', 'OR-130111',\n",
    "       'OR-130131', 'OR-101002', 'OR-180002', 'OSA-180002']], index = X_test_destandardized.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a598fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred_MARS = np.array(pd.read_excel('y_pred.xlsx')).ravel()\n",
    "\n",
    "# data_for_plotting = pd.DataFrame({'y_true':np.concatenate([np.array(y_test),np.array(y_train_val)]).ravel(),\n",
    "#  'y_pred_rnd_for_no_grid':np.concatenate([np.array(rnd_reg.predict(X_test)),np.array(rnd_reg.predict(X_train_val))]),\n",
    "# 'y_pred_MARS':y_pred_MARS,\n",
    "#  'Value formatted':np.array(pd.concat([X_test_destandardized['Value formatted'], X_train_val_destandardized['Value formatted']], axis=0)).ravel(),\n",
    "#  'Unified contribution formatted':np.array(pd.concat([X_test_destandardized['Unified Contribution formatted'], X_train_val_destandardized['Unified Contribution formatted']], axis=0)).ravel(),\n",
    "# 'train_test':np.concatenate([np.repeat('test',y_test.shape[0]),np.repeat('train',y_train_val.shape[0])])})\n",
    "\n",
    "# data_for_plotting.to_excel('data_for_plotting.xlsx')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "COdovl5oSNZk",
   "metadata": {
    "id": "COdovl5oSNZk"
   },
   "source": [
    "#### With grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af50184b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf = RandomForestClassifier(warm_start=True)\n",
    "# number_of_checkpoints = 10\n",
    "\n",
    "# for checkpoint in range(number_of_checkpoints):\n",
    "\n",
    "#     # Load only a subset of the data and train on it\n",
    "#     X, y = load_data_batch(batches=number_of_checkpoints, current_batch=checkpoint)\n",
    "#     clf.fit(X, y)\n",
    "\n",
    "#     # Save model checkpoint for each fit\n",
    "#     with open('path/to/models/random_forest_ckp_{}.p'.format(checkpoint), 'wb') as f:\n",
    "#         pickle.dump(clf, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8097acd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rnd_reg_grid = RandomForestRegressor(criterion='absolute_error',\n",
    "                                random_state=42)\n",
    "\n",
    "param_grid = [{'max_depth':np.arange(1,100,10),\n",
    "               'min_samples_split':np.arange(5,100,10),\n",
    "               'min_samples_leaf':np.arange(100,500,10),\n",
    "               'n_estimators':np.arange(10,150,15)}]\n",
    "\n",
    "rnd_search_cv = RandomizedSearchCV(estimator=rnd_reg_grid, param_distributions=param_grid,\n",
    "                                   n_iter=100, scoring='neg_mean_absolute_error',\n",
    "                                   n_jobs=-1, cv=5, random_state=42)\n",
    "\n",
    "rnd_search_cv.fit(X_train_val, np.array(y_train_val).ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe76ad9d",
   "metadata": {
    "id": "fe76ad9d"
   },
   "source": [
    "## <a style=background:yellow;color:black id='xgboost'> XGBoost</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25089e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d8a0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [{'gamma':[0.5,1,1.5,2,5],\n",
    "\n",
    "              'max_depth': [5,6,9,10],\n",
    "\n",
    "               'subsample' : [0.6,0.8,1],\n",
    "\n",
    "               'colsample_bytree' : [0.6,0.8,1],\n",
    "\n",
    "               'min_child_weight' : [1,5,10]\n",
    "\n",
    "               }]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "febc18f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_reg = xgboost.XGBRegressor(random_state = 42,learning_rate = 0.02,n_estimators = 500)\n",
    "\n",
    "grid_search = GridSearchCV(xgb_reg, param_grid=param_grid, cv=5,\n",
    "\n",
    "                          scoring='neg_mean_squared_error',\n",
    "\n",
    "                          return_train_score=True,n_jobs=-1)\n",
    "\n",
    "\n",
    "\n",
    "grid_search.fit(X_train_val,y_train_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a036d754",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = grid_search.best_estimator_\n",
    "\n",
    "final_model\n",
    "\n",
    " \n",
    "\n",
    "y_pred_test = final_model.predict(X_test)\n",
    "\n",
    " \n",
    "\n",
    "print(mean_absolute_error(y_pred_test, y_test))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "37bce5c1",
   "metadata": {},
   "source": [
    "## <a style=background:yellow;color:black id='neural_network'> Neural Network </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b150b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823022a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e616b741",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scheduler(epoch, lr):\n",
    "    if epoch < 3:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr * tf.math.exp(-0.025)\n",
    "\n",
    "def get_run_logdir(root_logdir, model_name):\n",
    "    import time\n",
    "    run_id = time.strftime('run_%Y_%m_%d-%H_%M_%S')\n",
    "    return os.path.join(root_logdir, model_name+'_'+run_id)\n",
    "\n",
    "model_name = input('Enter model name: ')\n",
    "root_logdir = os.path.join(os.curdir, 'my_logs')\n",
    "run_logdir = get_run_logdir(root_logdir, model_name)\n",
    "\n",
    "lr_schedule_cb = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
    "early_stop_cb = tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir,\n",
    "                                            histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4dc5342",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(64, activation=\"relu\", kernel_initializer=\"he_normal\",input_shape=X_train.shape[1:]),\n",
    "    keras.layers.Dropout(0.1),\n",
    "    keras.layers.Dense(128, activation='relu', kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.Dropout(0.1),\n",
    "    keras.layers.Dense(64, activation='relu', kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.Dropout(0.1),\n",
    "    keras.layers.Dense(30, activation=\"relu\", kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(loss='mae', optimizer=keras.optimizers.Adam(learning_rate=0.015))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae17809",
   "metadata": {
    "id": "eae17809"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "   1/2174 [..............................] - ETA: 13:24 - loss: 1867.6157"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-06 16:33:40.588529: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2174/2174 [==============================] - ETA: 0s - loss: 964.7441"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-06 16:33:56.485004: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2174/2174 [==============================] - 18s 8ms/step - loss: 964.7441 - val_loss: 837.1615 - lr: 0.0150\n",
      "Epoch 2/100\n",
      "2174/2174 [==============================] - 18s 8ms/step - loss: 873.2938 - val_loss: 804.3616 - lr: 0.0150\n",
      "Epoch 3/100\n",
      "2174/2174 [==============================] - 18s 8ms/step - loss: 819.5247 - val_loss: 783.8688 - lr: 0.0150\n",
      "Epoch 4/100\n",
      "2174/2174 [==============================] - 17s 8ms/step - loss: 805.0806 - val_loss: 801.3229 - lr: 0.0146\n",
      "Epoch 5/100\n",
      "2174/2174 [==============================] - 17s 8ms/step - loss: 796.4367 - val_loss: 763.3332 - lr: 0.0143\n",
      "Epoch 6/100\n",
      "2174/2174 [==============================] - 17s 8ms/step - loss: 785.6009 - val_loss: 780.0681 - lr: 0.0139\n",
      "Epoch 7/100\n",
      "2174/2174 [==============================] - 17s 8ms/step - loss: 780.2454 - val_loss: 797.9166 - lr: 0.0136\n",
      "Epoch 8/100\n",
      "2174/2174 [==============================] - 17s 8ms/step - loss: 774.9782 - val_loss: 785.1261 - lr: 0.0132\n",
      "Epoch 9/100\n",
      "2174/2174 [==============================] - 17s 8ms/step - loss: 773.1640 - val_loss: 789.6198 - lr: 0.0129\n",
      "Epoch 10/100\n",
      "2174/2174 [==============================] - 17s 8ms/step - loss: 767.3109 - val_loss: 765.3927 - lr: 0.0126\n",
      "Epoch 11/100\n",
      "2174/2174 [==============================] - 17s 8ms/step - loss: 764.2556 - val_loss: 752.5104 - lr: 0.0123\n",
      "Epoch 12/100\n",
      "2174/2174 [==============================] - 18s 8ms/step - loss: 761.6340 - val_loss: 754.0703 - lr: 0.0120\n",
      "Epoch 13/100\n",
      "2174/2174 [==============================] - 17s 8ms/step - loss: 757.1649 - val_loss: 788.3210 - lr: 0.0117\n",
      "Epoch 14/100\n",
      "2174/2174 [==============================] - 17s 8ms/step - loss: 759.5493 - val_loss: 782.7412 - lr: 0.0114\n",
      "Epoch 15/100\n",
      "2174/2174 [==============================] - 17s 8ms/step - loss: 752.6258 - val_loss: 763.4566 - lr: 0.0111\n",
      "Epoch 16/100\n",
      "2174/2174 [==============================] - 18s 8ms/step - loss: 752.0539 - val_loss: 754.9710 - lr: 0.0108\n",
      "Epoch 17/100\n",
      "2174/2174 [==============================] - 17s 8ms/step - loss: 751.2558 - val_loss: 746.5344 - lr: 0.0106\n",
      "Epoch 18/100\n",
      "2174/2174 [==============================] - 17s 8ms/step - loss: 756.6462 - val_loss: 751.8587 - lr: 0.0103\n",
      "Epoch 19/100\n",
      "2174/2174 [==============================] - 17s 8ms/step - loss: 747.6647 - val_loss: 754.3956 - lr: 0.0101\n",
      "Epoch 20/100\n",
      "2174/2174 [==============================] - 18s 8ms/step - loss: 746.6747 - val_loss: 757.9788 - lr: 0.0098\n",
      "Epoch 21/100\n",
      "2174/2174 [==============================] - 17s 8ms/step - loss: 746.9993 - val_loss: 761.2542 - lr: 0.0096\n",
      "Epoch 22/100\n",
      "2174/2174 [==============================] - 17s 8ms/step - loss: 743.7657 - val_loss: 758.7889 - lr: 0.0093\n",
      "Epoch 23/100\n",
      "2174/2174 [==============================] - 17s 8ms/step - loss: 740.7918 - val_loss: 752.2412 - lr: 0.0091\n",
      "Epoch 24/100\n",
      "2174/2174 [==============================] - 17s 8ms/step - loss: 742.3972 - val_loss: 751.4749 - lr: 0.0089\n",
      "Epoch 25/100\n",
      "2174/2174 [==============================] - 18s 8ms/step - loss: 756.1424 - val_loss: 761.3017 - lr: 0.0087\n",
      "Epoch 26/100\n",
      "2174/2174 [==============================] - 17s 8ms/step - loss: 739.2769 - val_loss: 758.6144 - lr: 0.0084\n",
      "Epoch 27/100\n",
      "2174/2174 [==============================] - 17s 8ms/step - loss: 737.0274 - val_loss: 759.9973 - lr: 0.0082\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=100, validation_data=(X_val, y_val),callbacks=[tensorboard_cb, lr_schedule_cb, early_stop_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ecaf48",
   "metadata": {
    "id": "73ecaf48"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all\n",
      "TensorBoard 2.9.1 at http://localhost:6006/ (Press CTRL+C to quit)\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!tensorboard --logdir=./my_logs --port=6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77ff69f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 75/302 [======>.......................] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-06 16:41:37.173969: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "302/302 [==============================] - 1s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "768.7058876937961"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "mean_absolute_error(y_test, model.predict(X_test))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7a43cc51",
   "metadata": {},
   "source": [
    "## <a style=background:yellow;color:black> Oversampling </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5b045f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_val_inv_trans = pd.DataFrame(std_scale.inverse_transform(X_train_val[['Number of Lawyers','Number of Legal Parties', 'Value formatted',\n",
    "       'Unified Contribution formatted']]), columns = ['Number of Lawyers','Number of Legal Parties', 'Value formatted',\n",
    "       'Unified Contribution formatted'], index = X_train_val.index)\n",
    "\n",
    "X_test_inv_trans = pd.DataFrame(std_scale.inverse_transform(X_test[['Number of Lawyers','Number of Legal Parties', 'Value formatted',\n",
    "       'Unified Contribution formatted']]), columns = ['Number of Lawyers','Number of Legal Parties', 'Value formatted',\n",
    "       'Unified Contribution formatted'], index=X_test.index)\n",
    "\n",
    "X_train_val_not_std = X_train_val[['Tax Related','Milano', 'Bari', 'Bologna', 'Genova',\n",
    "       'Palermo', 'Napoli', 'Torino', 'Trento', 'Roma', \"L'Aquila\", 'Potenza',\n",
    "       'Perugia', 'Campobasso', 'Firenze', 'Cagliari', 'Venezia', 'Cosenza',\n",
    "       'Ancona', 'Trieste', 'Aosta','OR-140999', 'OR-145009', 'OR-139999',\n",
    "       'OR-145999', 'OR-130099', 'OR-101003', 'OR-130121', 'OR-130111',\n",
    "       'OR-130131', 'OR-101002', 'OR-180002', 'OSA-180002']]\n",
    "\n",
    "X_test_not_std = X_test[['Tax Related','Milano', 'Bari', 'Bologna', 'Genova',\n",
    "       'Palermo', 'Napoli', 'Torino', 'Trento', 'Roma', \"L'Aquila\", 'Potenza',\n",
    "       'Perugia', 'Campobasso', 'Firenze', 'Cagliari', 'Venezia', 'Cosenza',\n",
    "       'Ancona', 'Trieste', 'Aosta','OR-140999', 'OR-145009', 'OR-139999',\n",
    "       'OR-145999', 'OR-130099', 'OR-101003', 'OR-130121', 'OR-130111',\n",
    "       'OR-130131', 'OR-101002', 'OR-180002', 'OSA-180002']]\n",
    "\n",
    "X_train_val_destandardized = pd.concat([X_train_val_inv_trans, X_train_val_not_std],axis=1)\n",
    "X_test_destandardized = pd.concat([X_test_inv_trans, X_test_not_std],axis=1)\n",
    "\n",
    "X_train_val_destandardized = pd.DataFrame(np.array(X_train_val_destandardized), columns=[['Number of Lawyers',\n",
    "     'Number of Legal Parties', 'Value formatted',\n",
    "       'Unified Contribution formatted', 'Tax Related','Milano', 'Bari', 'Bologna', 'Genova',\n",
    "       'Palermo', 'Napoli', 'Torino', 'Trento', 'Roma', \"L'Aquila\", 'Potenza',\n",
    "       'Perugia', 'Campobasso', 'Firenze', 'Cagliari', 'Venezia', 'Cosenza',\n",
    "       'Ancona', 'Trieste', 'Aosta','OR-140999', 'OR-145009', 'OR-139999',\n",
    "       'OR-145999', 'OR-130099', 'OR-101003', 'OR-130121', 'OR-130111',\n",
    "       'OR-130131', 'OR-101002', 'OR-180002', 'OSA-180002']], index = X_train_val_destandardized.index)\n",
    "\n",
    "X_test_destandardized = pd.DataFrame(np.array(X_test_destandardized), columns=[['Number of Lawyers',\n",
    "     'Number of Legal Parties', 'Value formatted',\n",
    "       'Unified Contribution formatted', 'Tax Related','Milano', 'Bari', 'Bologna', 'Genova',\n",
    "       'Palermo', 'Napoli', 'Torino', 'Trento', 'Roma', \"L'Aquila\", 'Potenza',\n",
    "       'Perugia', 'Campobasso', 'Firenze', 'Cagliari', 'Venezia', 'Cosenza',\n",
    "       'Ancona', 'Trieste', 'Aosta','OR-140999', 'OR-145009', 'OR-139999',\n",
    "       'OR-145999', 'OR-130099', 'OR-101003', 'OR-130121', 'OR-130111',\n",
    "       'OR-130131', 'OR-101002', 'OR-180002', 'OSA-180002']], index = X_test_destandardized.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe947fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_val_destandardized = pd.concat([X_train_val_destandardized, y_train_val],names=list(X_train_val_destandardized.columns)+['Settlemnet'],axis=1)\n",
    "data_train_val_destandardized_5200_26000 = data_train_val_destandardized.loc[(data_train_val_destandardized[('Value formatted',)]>5200) & (data_train_val_destandardized[('Value formatted',)]<= 26000)]\n",
    "\n",
    "oversampled_5200_26000_train_val = pd.DataFrame(columns=list(data_train_val_destandardized_5200_26000.columns))\n",
    "for i in range(4):\n",
    "    mask = np.random.choice(data_train_val_destandardized_5200_26000.shape[0], data_train_val_destandardized_5200_26000.shape[0])\n",
    "    oversampled_5200_26000_train_val = oversampled_5200_26000_train_val.append(data_train_val_destandardized_5200_26000.iloc[mask])\n",
    "\n",
    "final_oversampled = data_train_val_destandardized.loc[(data_train_val_destandardized[('Value formatted',)]<=5200) | (data_train_val_destandardized[('Value formatted',)]> 26000)]\\\n",
    "    .append(oversampled_5200_26000_train_val)\n",
    "\n",
    "# final_oversampled.to_excel('final_oversampled.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d5defb",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_oversampled = pd.read_excel('final_oversampled.xlsx').drop('Unnamed: 0',axis=1)\n",
    "\n",
    "X_y_train_val_oversampled = pd.DataFrame(np.array(final_oversampled), columns=[['Number of Lawyers',\n",
    "     'Number of Legal Parties', 'Value formatted',\n",
    "       'Unified Contribution formatted', 'Tax Related','Milano', 'Bari', 'Bologna', 'Genova',\n",
    "       'Palermo', 'Napoli', 'Torino', 'Trento', 'Roma', \"L'Aquila\", 'Potenza',\n",
    "       'Perugia', 'Campobasso', 'Firenze', 'Cagliari', 'Venezia', 'Cosenza',\n",
    "       'Ancona', 'Trieste', 'Aosta','OR-140999', 'OR-145009', 'OR-139999',\n",
    "       'OR-145999', 'OR-130099', 'OR-101003', 'OR-130121', 'OR-130111',\n",
    "       'OR-130131', 'OR-101002', 'OR-180002', 'OSA-180002','Settlement']], index = final_oversampled.index)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ead8f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j3/6zzd1jr16pb3yxx70_376pmw0000gn/T/ipykernel_1271/1131710983.py:4: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  X_oversamp = X_y_train_val_oversampled.drop('Settlement',axis=1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_oversamp = X_y_train_val_oversampled.drop('Settlement',axis=1)\n",
    "y_oversamp = X_y_train_val_oversampled['Settlement']\n",
    "y_oversamp = pd.DataFrame(y_oversamp)\n",
    "\n",
    "X_to_scale_oversamp = X_oversamp[['Number of Lawyers','Number of Legal Parties', 'Value formatted',\n",
    "       'Unified Contribution formatted']]\n",
    "X_not_to_scale_oversamp  = X_oversamp[['Tax Related','Milano', 'Bari', 'Bologna', 'Genova',\n",
    "       'Palermo', 'Napoli', 'Torino', 'Trento', 'Roma', \"L'Aquila\", 'Potenza',\n",
    "       'Perugia', 'Campobasso', 'Firenze', 'Cagliari', 'Venezia', 'Cosenza',\n",
    "       'Ancona', 'Trieste', 'Aosta','OR-140999', 'OR-145009', 'OR-139999',\n",
    "       'OR-145999', 'OR-130099', 'OR-101003', 'OR-130121', 'OR-130111',\n",
    "       'OR-130131', 'OR-101002', 'OR-180002', 'OSA-180002']]\n",
    "\n",
    "std_scale = StandardScaler()\n",
    "X_scaled_oversamp  = std_scale.fit_transform(X_to_scale_oversamp )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195c5af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled_df_oversamp  = pd.DataFrame(X_scaled_oversamp , columns=[X_to_scale_oversamp.columns.tolist()])\n",
    "X_scaled_df_oversamp  = pd.concat([X_scaled_df_oversamp, X_not_to_scale_oversamp], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8c9243",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_val_oversamp, X_test_oversamp, y_train_val_oversamp, y_test_oversamp = train_test_split(X_scaled_df_oversamp,\n",
    "                                                            y_oversamp, random_state=0,test_size=0.1)\n",
    "\n",
    "X_train_oversamp, X_val_oversamp, y_train_oversamp, y_val_oversamp = train_test_split(X_train_val_oversamp,\n",
    "                                                             y_train_val_oversamp,random_state=0,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be415226",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import os\n",
    "\n",
    "def scheduler(epoch, lr):\n",
    "    if epoch < 3:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr * tf.math.exp(-0.025)\n",
    "\n",
    "def get_run_logdir(root_logdir, model_name):\n",
    "    import time\n",
    "    run_id = time.strftime('run_%Y_%m_%d-%H_%M_%S')\n",
    "    return os.path.join(root_logdir, model_name+'_'+run_id)\n",
    "\n",
    "model_name = input('Enter model name: ')\n",
    "root_logdir = os.path.join(os.curdir, 'my_logs')\n",
    "run_logdir = get_run_logdir(root_logdir, model_name)\n",
    "\n",
    "lr_schedule_cb = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
    "early_stop_cb = tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir,\n",
    "                                            histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553864dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "keras.backend.clear_session()\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(64, activation=\"relu\", kernel_initializer=\"he_normal\",input_shape=X_train.shape[1:]),\n",
    "    keras.layers.Dropout(0.1),\n",
    "    keras.layers.Dense(128, activation='relu', kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.Dropout(0.1),\n",
    "    keras.layers.Dense(64, activation='relu', kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.Dropout(0.1),\n",
    "    keras.layers.Dense(30, activation=\"relu\", kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(loss='mae', optimizer=keras.optimizers.Adam(learning_rate=0.015))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ecfc956",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train_oversamp, y_train_oversamp, epochs=100, validation_data=(X_val_oversamp, y_val_oversamp),callbacks=[tensorboard_cb, lr_schedule_cb, early_stop_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3ba329",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_for_plotting = pd.read_excel('data_for_plotting.xlsx')\n",
    "# data_for_plotting['y_pred_neural_network_oversamp'] = np.concatenate([np.array(model.predict(X_test)),np.array(model.predict(X_train_val))])\n",
    "# data_for_plotting.to_excel('data_for_plotting.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "28d2d24dc05509bf292e34803b47a1e549616d0bedf6bebdafbe5e542b7fb512"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
