{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a style = background:lightgreen;color:black>Outcome and Duration Prediction on train_od (modeling) </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../DATA/final_train_od_dummies.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have to encode target (Outcome) labels with value between 0 and n_classes-1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "le.fit(np.array(data['Outcome']).ravel())\n",
    "data['Outcome'] = le.transform(np.array(data['Outcome']).ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[['Tax Related', 'Number of Lawyers',\n",
    "     'Number of Legal Parties', 'Value formatted',\n",
    "       'Unified Contribution formatted', 'Milano', 'Bari', 'Bologna', 'Genova',\n",
    "       'Palermo', 'Napoli', 'Torino', 'Trento', 'Roma', \"L'Aquila\", 'Potenza',\n",
    "       'Perugia', 'Campobasso', 'Firenze', 'Cagliari', 'Venezia', 'Cosenza',\n",
    "       'Ancona', 'Trieste', 'Aosta','OR-140999', 'OR-145009', 'OR-139999',\n",
    "       'OR-145999', 'OR-130099', 'OR-101003', 'OR-130121', 'OR-130111',\n",
    "       'OR-130131', 'OR-101002', 'OR-180002', 'OSA-180002','OSA-180099','OSA-180001','OSA-140999','OSA-145999']]\n",
    "\n",
    "y = data[['Duration', 'Outcome']]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a style=background:yellow;color:black> Standardization and Split in training, validation and testing set </a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You need to scale just the variables that are neither dummies nor boolean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_to_scale = X[['Number of Lawyers','Number of Legal Parties', 'Value formatted',\n",
    "       'Unified Contribution formatted']]\n",
    "X_not_to_scale = X[['Tax Related','Milano', 'Bari', 'Bologna', 'Genova',\n",
    "       'Palermo', 'Napoli', 'Torino', 'Trento', 'Roma', \"L'Aquila\", 'Potenza',\n",
    "       'Perugia', 'Campobasso', 'Firenze', 'Cagliari', 'Venezia', 'Cosenza',\n",
    "       'Ancona', 'Trieste', 'Aosta','OR-140999', 'OR-145009', 'OR-139999',\n",
    "       'OR-145999', 'OR-130099', 'OR-101003', 'OR-130121', 'OR-130111',\n",
    "       'OR-130131', 'OR-101002', 'OR-180002', 'OSA-180002','OSA-180099','OSA-180001','OSA-140999','OSA-145999']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y = pd.DataFrame(y)\n",
    "std_scale = StandardScaler()\n",
    "X_scaled = std_scale.fit_transform(X_to_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled_df = pd.DataFrame(X_scaled, columns=[X_to_scale.columns])\n",
    "X_scaled_df = pd.concat([X_scaled_df, X_not_to_scale], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X_scaled_df, y, random_state=0,\n",
    "                                                            test_size=0.1)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val,random_state=0,\n",
    "                                                            test_size=0.2  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_val = pd.DataFrame(np.array(X_train_val), columns=[['Number of Lawyers','Number of Legal Parties', \n",
    "       'Value formatted','Unified Contribution formatted', 'Tax Related','Milano', 'Bari', 'Bologna', 'Genova',\n",
    "       'Palermo', 'Napoli', 'Torino', 'Trento', 'Roma', \"L'Aquila\", 'Potenza',\n",
    "       'Perugia', 'Campobasso', 'Firenze', 'Cagliari', 'Venezia', 'Cosenza',\n",
    "       'Ancona', 'Trieste', 'Aosta','OR-140999', 'OR-145009', 'OR-139999',\n",
    "       'OR-145999', 'OR-130099', 'OR-101003', 'OR-130121', 'OR-130111',\n",
    "       'OR-130131', 'OR-101002', 'OR-180002', 'OSA-180002',\n",
    "       'OSA-180099','OSA-180001','OSA-140999','OSA-145999']], index = X_train_val.index)\n",
    "\n",
    "\n",
    "X_test = pd.DataFrame(np.array(X_test), columns=[['Number of Lawyers','Number of Legal Parties', \n",
    "       'Value formatted','Unified Contribution formatted', 'Tax Related','Milano', 'Bari', 'Bologna', 'Genova',\n",
    "       'Palermo', 'Napoli', 'Torino', 'Trento', 'Roma', \"L'Aquila\", 'Potenza',\n",
    "       'Perugia', 'Campobasso', 'Firenze', 'Cagliari', 'Venezia', 'Cosenza',\n",
    "       'Ancona', 'Trieste', 'Aosta','OR-140999', 'OR-145009', 'OR-139999',\n",
    "       'OR-145999', 'OR-130099', 'OR-101003', 'OR-130121', 'OR-130111',\n",
    "       'OR-130131', 'OR-101002', 'OR-180002', 'OSA-180002',\n",
    "       'OSA-180099','OSA-180001','OSA-140999','OSA-145999']], index = X_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_val_duration = y_train_val['Duration']\n",
    "y_train_val_Outcome = y_train_val['Outcome']\n",
    "y_test_duration = y_test['Duration']\n",
    "y_test_Outcome = y_test['Outcome']\n",
    "y_train_duration = y_train['Duration']\n",
    "y_train_Outcome = y_train['Outcome']\n",
    "y_val_duration = y_val['Duration']\n",
    "y_val_Outcome = y_val['Outcome']\n",
    "y_train_val_duration = pd.DataFrame(y_train_val_duration)\n",
    "y_train_val_Outcome = pd.DataFrame(y_train_val_Outcome)\n",
    "y_test_duration = pd.DataFrame(y_test_duration)\n",
    "y_test_Outcome = pd.DataFrame(y_test_Outcome)\n",
    "y_train_duration = pd.DataFrame(y_train_duration)\n",
    "y_train_Outcome = pd.DataFrame(y_train_Outcome )\n",
    "y_val_duration = pd.DataFrame(y_val_duration)\n",
    "y_val_Outcome = pd.DataFrame(y_val_Outcome)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "18ae4bfb",
   "metadata": {},
   "source": [
    "# <a style=background:yellow;color:black> Models <a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d1d472ad",
   "metadata": {},
   "source": [
    "## <a style=background:yellow;color:black> Random forest </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools as it\n",
    "import os\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "# import shutil\n",
    "\n",
    "param_grid = {'max_depth':np.arange(1,8),\n",
    "               'min_samples_split':np.arange(5,100,10),\n",
    "               'min_samples_leaf':np.arange(5,100,10),\n",
    "               'n_estimators':np.arange(1,500,50)}\n",
    "\n",
    "\n",
    "allNames = sorted(param_grid)\n",
    "combinations = it.product(*(param_grid[Name] for Name in allNames))\n",
    "combinations = list(combinations)\n",
    "\n",
    "df = pd.DataFrame(combinations, columns=param_grid.keys())\n",
    "\n",
    "start_point = int(input('START POINT:'))\n",
    "end_point = int(input('END POINT:'))\n",
    "\n",
    "\n",
    "#shutil.rmtree('/content/drive/MyDrive/RFC')\n",
    "#os.makedirs('/content/drive/MyDrive/RFC')\n",
    "\n",
    "# FROM 6000 to 6400 (RUNNING)\n",
    "best_f1 = np.load('../RFC/'+os.listdir('../RFC')[-1],allow_pickle=True)[1] \n",
    "for i in range(start_point,end_point):\n",
    "  clf = RandomForestClassifier(max_depth = df.iloc[i][0],\n",
    "                               min_samples_split = df.iloc[i][1],\n",
    "                               min_samples_leaf = df.iloc[i][2],\n",
    "                               n_estimators = df.iloc[i][3],\n",
    "                               class_weight = 'balanced',\n",
    "                               n_jobs=1)\n",
    "  clf.fit(X_train_val, np.array(y_train_val_Outcome).ravel())\n",
    "  clf_val = np.array([clf.get_params(), f1_score(np.array(y_test_Outcome).ravel(),clf.predict(X_test), average = 'weighted')])\n",
    "  if clf_val[1]>best_f1:\n",
    "    best_f1 = clf_val[1]\n",
    "    #np.save(os.path.join('/content/drive/MyDrive/RFC/', 'best_up_to_' + str(i)), clf_val)\n",
    "    np.save(os.path.join('../RFC', 'best_up_to_'+str(i)),clf_val)\n",
    "  else:\n",
    "    # os.rename('/content/drive/MyDrive/RFC/' + os.listdir('/content/drive/MyDrive/RFC/')[-1],\n",
    "    #           os.path.join('/content/drive/MyDrive/RFC/', 'best_up_to_' + str(i) + '.npy'))\n",
    "    os.rename('../RFC/'+os.listdir('../RFC')[-1], os.path.join('../RFC', 'best_up_to_'+str(i)+'.npy'))\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f1d44acd",
   "metadata": {},
   "source": [
    "## <a style=background:yellow;color:black> Neural Network</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af63687",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# carica i dati\n",
    "X = np.load('data_features.npy')\n",
    "y = np.load('data_labels.npy')\n",
    "\n",
    "# converte la variabile da predire in numerica\n",
    "encoder = LabelEncoder()\n",
    "y = encoder.fit_transform(y)\n",
    "\n",
    "# divide i dati in training e test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# converte le etichette in formato one-hot\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "# crea il modello\n",
    "model = Sequential()\n",
    "model.add(Dense(10, input_dim=X.shape[1], activation='relu'))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "\n",
    "# compila il modello\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# addestra il modello\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# effettua le predizioni\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# calcola l'f1 score\n",
    "score = f1_score(y_test, y_pred, average='micro')\n",
    "print(score)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Adri_Env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8 | packaged by conda-forge | (main, Nov 22 2022, 08:25:29) [Clang 14.0.6 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "28d2d24dc05509bf292e34803b47a1e549616d0bedf6bebdafbe5e542b7fb512"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
